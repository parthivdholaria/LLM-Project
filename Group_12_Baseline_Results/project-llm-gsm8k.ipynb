{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install bitsandbytes\n!pip install transformers\n!pip install datasets\n!pip install groqflow\n!pip install accelerate\n!pip install groq\n!pip install langchain\n!pip install langchain-community\n!pip install wolframalpha\n!pip install -qU langchain-groq\n!pip install -qU langchain-anthropic\n!pip install -qU langchain_mistralai","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load the gsm8k dataset\ndataset = load_dataset(\"openai/gsm8k\",'main')\n\n# Display the first few rows\nprint(dataset)\nprint(dataset['train'][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from langchain_mistralai import ChatMistralAI\nfrom kaggle_secrets import UserSecretsClient\nfrom langchain_groq import ChatGroq\nfrom langchain.agents import load_tools\nfrom langchain.agents import AgentExecutor,create_react_agent,initialize_agent,AgentType,Tool\nfrom langchain_anthropic import ChatAnthropic\nllm = ChatGroq(\n    model=\"mixtral-8x7b-32768\",\n    temperature=0,\n    max_retries=2,\n    api_key=\"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\"\n)\n\n\n\ntools = load_tools([\"llm-math\"], llm=llm)\nagent = initialize_agent(tools, llm, agent_type=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,handle_parsing_errors=True, verbose=True)\nmessages = [\n    (\n        \"system\",\n        \"You are a helpful assistant that does simple maths calculations. You have access to tools like caculators and wolfram alpha?\"\n        \"If you need to use a tool, state the action clearly first, then wait for the result before providing the final answer. \"\n        \"Do not provide the final answer until you have received all necessary observations from the tools.\",\n    ),\n    (\"human\", \"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\"),\n]\nresult = agent.run(messages)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nfrom io import StringIO\nfrom transformers import TextIteratorStreamer\nimport sys\nimport re\nimport io\ndef run_and_capture(prompt, react_agent):\n    # Create a string buffer to capture the output\n    captured_output = io.StringIO()\n    \n    # Save the original stdout\n    original_stdout = sys.stdout\n    \n    try:\n        # Redirect stdout to the buffer\n        sys.stdout = captured_output\n\n        # Run the agent with the provided prompt\n        result = react_agent.run(prompt)\n        \n        # Ensure the captured output is written to original stdout (console)\n        original_stdout.write(captured_output.getvalue())\n\n    finally:\n        # Reset stdout to its original state\n        sys.stdout = original_stdout\n    \n    # Get the captured verbose output\n    verbose_output = captured_output.getvalue()\n    return verbose_output\ndef extract_final_answer_2(thought_process):\n    # Split the text by lines to process each line separately\n    lines = thought_process.strip().splitlines()\n    \n    final_observation = None  # To store the last valid observation before the final answer\n    found_final_answer = False\n    \n    # Traverse through the lines to identify and extract the relevant parts\n    for line in lines:\n        # Check if the line is an observation\n        if line.startswith(\"Observation:\"):\n            # Extract the answer from the observation\n            observation_match = re.search(r\"Answer:\\s*([\\d\\.]+)\", line)\n            if observation_match:\n                final_observation = observation_match.group(1)  # Update the final observation\n            \n        # Check if the line contains \"Thought:Final Answer:\"\n        if \"Final Answer:\" in line:\n            \n            break  # Stop processing further since we found the final answer thought\n\n    # Return the final observation found before the final answer\n    return final_observation\ndef extract_final_answer(thought_process):\n    # Split the text by lines to process each line separately\n    lines = thought_process.strip().splitlines()\n    \n    # Traverse through the lines to identify and extract the relevant final answer\n    for line in lines:\n        # Check if the line contains \"Final Answer:\"\n        if \"Final Answer:\" in line:\n            # Extract only the number from the final answer line\n            final_answer_match = re.search(r\"Final Answer:.*?([\\d\\.]+)\", line)\n            if final_answer_match:\n                return final_answer_match.group(1).strip()\n    \n    # Return None if no final answer is found\n    return None\ndef extract_final_answer_from_answer(output):\n    # Use a regular expression to capture the answer after \"####\"\n    match = re.search(r\"####\\s*(\\d+)\", output)\n    \n    if match:\n        return match.group(1)  # Return the captured answer\n    else:\n        return None  # Return None if the answer is not found","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nllm = ChatGroq(\n    model=\"mixtral-8x7b-32768\",\n    temperature=0,\n    max_retries=2,\n    api_key=\"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\"\n)\ntools = load_tools([\"llm-math\",\"wolfram-alpha\"],wolfram_alpha_appid=\"4L7YU5-AU95ELH8ER\", llm=llm)\nagent = initialize_agent(tools, llm, agent_type=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,handle_parsing_errors=True, verbose=True,max_iterations=3)\nnum_correct=0\ninvalid_extractions=0\ntotal=0\nfor idx, entry in enumerate(dataset[\"train\"]):\n    question = entry[\"question\"]\n    answer = entry[\"answer\"]\n    correct_answer= extract_final_answer_from_answer(answer)\n    total+=1\n    messages = [\n        (\n            \"system\",\n            \"You are a helpful assistant that does simple maths calculations. You have access to tools like caculators and wolfram alpha?\"\n            \"If you need to use a tool, state the action clearly first, then wait for the result before providing the final answer. \"\n            \"Do not provide the final answer until you have received all necessary observations from the tools.\"\n            \"Please ensure the final answer is only a single number without any units or statements.\",\n        ),\n        (\"human\", question),\n    ]\n    try:\n        result = run_and_capture(messages,agent)\n        generated_answer=extract_final_answer(result)\n        if correct_answer is not None and generated_answer is not None:\n            correct_answer_int = int(float(correct_answer))\n            generated_answer_int = int(float(generated_answer))\n                # Compare the integer values\n            if correct_answer_int == generated_answer_int:\n                num_correct+=1\n                print(\"Yay\")\n        else:\n            invalid_extractions+=1\n            print(\"----------------------------------------------------\")\n    except:\n        invalid_extractions+=1\n        result=\"\"\n    if(idx>=100):\n        break\n\naccuracy=(num_correct/(total-invalid_extractions))*100\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Invalid extractions {invalid_extractions}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nllm = ChatGroq(\n    model=\"gemma2-9b-it\",\n    temperature=0,\n    max_retries=2,\n    api_key=\"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\"\n)\ntools = load_tools([\"llm-math\",\"wolfram-alpha\"],wolfram_alpha_appid=\"4L7YU5-AU95ELH8ER\", llm=llm)\nagent = initialize_agent(tools, llm, agent_type=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,handle_parsing_errors=True, verbose=True)\nnum_correct=0\ninvalid_extractions=0\ntotal=0\nfor idx, entry in enumerate(dataset[\"train\"]):\n    question = entry[\"question\"]\n    answer = entry[\"answer\"]\n    correct_answer= extract_final_answer_from_answer(answer)\n    total+=1\n    messages = [\n        (\n            \"system\",\n            \"You are a helpful assistant that does simple maths calculations. You have access to tools like caculators and wolfram alpha?\"\n            \"If you need to use a tool, state the action clearly first, then wait for the result before providing the final answer. \"\n            \"Do not provide the final answer until you have received all necessary observations from the tools.\"\n            \"Please ensure the final answer is only a single number without any units or statements.\",\n        ),\n        (\"human\", question),\n    ]\n    try:\n        result = run_and_capture(messages,agent)\n        generated_answer=extract_final_answer(result)\n        if correct_answer is not None and generated_answer is not None:\n            correct_answer_int = int(float(correct_answer))\n            generated_answer_int = int(float(generated_answer))\n                # Compare the integer values\n            if correct_answer_int == generated_answer_int:\n                print(\"Yay\")\n                num_correct+=1\n        else:\n            invalid_extractions+=1\n            print(\"----------------------------------------------------\")\n    except Exception as e:\n        print(e)\n        invalid_extractions+=1\n        result=\"\"\n    if(idx>=100):\n        break\n\naccuracy=(num_correct/(total-invalid_extractions))*100\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Invalid extractions {invalid_extractions}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nllm = ChatGroq(\n    model=\"llama-3.1-8b-instant\",\n    temperature=0,\n    max_retries=2,\n    api_key=\"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\"\n)\ntools = load_tools([\"llm-math\",\"wolfram-alpha\"],wolfram_alpha_appid=\"4L7YU5-AU95ELH8ER\", llm=llm)\nagent = initialize_agent(tools, llm, agent_type=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,handle_parsing_errors=True, verbose=True)\nnum_correct=0\ninvalid_extractions=0\ntotal=0\nfor idx, entry in enumerate(dataset[\"train\"]):\n    question = entry[\"question\"]\n    answer = entry[\"answer\"]\n    correct_answer= extract_final_answer_from_answer(answer)\n    total+=1\n    messages = [\n        (\n            \"system\",\n            \"You are a helpful assistant that does simple maths calculations. You have access to tools like caculators and wolfram alpha?\"\n            \"If you need to use a tool, state the action clearly first, then wait for the result before providing the final answer. \"\n            \"Do not provide the final answer until you have received all necessary observations from the tools.\"\n            \"Please ensure the final answer is only a single number without any units or statements.\",\n        ),\n        (\"human\", question),\n    ]\n    try:\n        result = run_and_capture(messages,agent)\n        generated_answer=extract_final_answer_2(result)\n        if correct_answer is not None and generated_answer is not None:\n            correct_answer_int = int(float(correct_answer))\n            generated_answer_int = int(float(generated_answer))\n                # Compare the integer values\n            if correct_answer_int == generated_answer_int:\n                print(\"Yay\")\n                num_correct+=1\n        else:\n            invalid_extractions+=1\n            print(\"----------------------------------------------------\")\n    except:\n        invalid_extractions+=1\n        result=\"\"\n    if(idx>=100):\n        break\n\naccuracy=(num_correct/total)*100\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Invalid extractions {invalid_extractions}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}